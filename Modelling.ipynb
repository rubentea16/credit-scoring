{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ApSFjcpcYHbm",
    "outputId": "1523e4ca-a662-4b8d-bb02-f7669b5722fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV, GridSearchCV\n",
    "# machine learning\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import tree\n",
    "import pickle\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "from google.colab import files\n",
    "\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q1C-dPRpGvZx"
   },
   "source": [
    "# Load Data Preprocessing and Data Unpreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2wZgw3GYHbs"
   },
   "outputs": [],
   "source": [
    "data_preprocessing = pd.read_excel ('drive/My Drive/Colab Notebooks/credit_scoring/data_preprocessing.xlsx')\n",
    "data_unpreprocessing = pd.read_excel ('drive/My Drive/Colab Notebooks/credit_scoring/data_unpreprocessing.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "odSrR1EKYHbw"
   },
   "outputs": [],
   "source": [
    "# Pisahkan antara feature data dengan target data\n",
    "X_pre = data_preprocessing.drop(['CREDIT_SCORE'],axis=1).values\n",
    "y_pre = data_preprocessing['CREDIT_SCORE'].values\n",
    "##################################################\n",
    "X_unpre = data_unpreprocessing.drop(['CREDIT_SCORE'],axis=1).values\n",
    "y_unpre = data_unpreprocessing['CREDIT_SCORE'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O-DZ2YvLGx-n"
   },
   "source": [
    "## Split data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7vHQ71TTYHbz"
   },
   "outputs": [],
   "source": [
    "# Split data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pre, y_pre, test_size=0.2, shuffle=True)\n",
    "X_train_un, X_test_un, y_train_un, y_test_un = train_test_split(X_unpre, y_unpre, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EhpL-nK2Ieeb"
   },
   "source": [
    "# Insights about Dataset\n",
    "- Dataset is imbalanced\n",
    "- Data is non-linear\n",
    "- Dataset have outlier which is make-sense data (we not drop it)\n",
    "- Feature of dataset is almost everything was categorical type\n",
    "- Small Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAFcKtrhHiH3"
   },
   "source": [
    "# Reason behind choosen algorithm\n",
    "1. Because we have small dataset so we prefer use machine learning algorithm rather than neural network / deep learning\n",
    "2. Credit Scoring is classification case (predict class)\n",
    "3. Because of dataset is non-linear we use algorithm which can handle that and have good performance\n",
    "4. We try use CatBoost algorithm because feature of dataset is almost everything was categorical type\n",
    "\n",
    "Option : if you want to balance class in dataset, you can use SMOTE for over-sampling\n",
    "\n",
    "# Metric to evaluate performance of models\n",
    "I'm use F1-score which can give more insight into the accuracy of the model than traditional classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ohEyr9ZBYpXV"
   },
   "source": [
    "# Create Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ukrjv6vKoFXa"
   },
   "source": [
    "Model :\n",
    "- Support Vector Machine a.k.a SVM\n",
    "- Random Forest a.k.a RF\n",
    "- Extreme Gradient Boosting a.k.a XGBOOST\n",
    "- CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yk5kYVRdYoAf"
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"SVC\" : {\"algo\" : SVC(random_state=42),\n",
    "             \"parameter\" : {'C': [0.001, 0.10, 0.1, 10, 25, 50, 100, 1000],\n",
    "                            'gamma':[1e-2, 1e-3, 1e-4, 1e-5, 'auto'],\n",
    "                            'kernel':['poly','rbf','sigmoid']},\n",
    "                            'degree': [2, 3, 4]},\n",
    "\n",
    "    \"Random Forest\" : {\"algo\" : RandomForestClassifier(random_state=42),\n",
    "                       \"parameter\" : {\"n_estimators\" : [10, 20, 40, 60, 80, 100, 150],\n",
    "                                      \"criterion\" : ['gini', 'entropy'],\n",
    "                                      \"max_features\" : ['auto', 'sqrt', 'log2']} },\n",
    "    \n",
    "    \"XGBoost\" : {\"algo\" : XGBClassifier(random_state=42),\n",
    "                 \"parameter\" : {\"learning_rate\": np.arange(0.01, 0.2, 0.02),  \n",
    "                                \"colsample_bytree\": np.arange(0.7, 1, 0.05),\n",
    "                                \"max_depth\" : np.arange(4, 10, 1),\n",
    "                                \"n_estimators\": np.arange(100, 1000, 50),\n",
    "                                \"subsample\": np.arange(0.7, 1, 0.05),\n",
    "                                \"objective\": [\"binary:logistic\", \"binary:hinge\"],\n",
    "                                \"max_delta_step\": np.arange(0, 4, 1)} }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_mN0LEpdhkLZ"
   },
   "outputs": [],
   "source": [
    "def fine_tuning(model, model_param: dict, x_train, y_train, n_iteration, score, split):\n",
    "  search = RandomizedSearchCV(model, model_param, n_iter=n_iteration, scoring=score, cv=split, verbose=1, n_jobs=-1)\n",
    "  search.fit(x_train, y_train)\n",
    "  print(\"Model={} \\nScore={} \".format(model, search.best_score_))\n",
    "  metric = search.best_score_\n",
    "  best_param = search.best_estimator_\n",
    "  return best_param, metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ibQbPbsw1CgV"
   },
   "source": [
    "# Fine-Tuning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 870
    },
    "colab_type": "code",
    "id": "np-zz86BhOLe",
    "outputId": "95e160d8-4e82-41e2-adca-d1c95359cd70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 120 is smaller than n_iter=250. Running 120 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:    6.6s finished\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 42 is smaller than n_iter=250. Running 42 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=42,\n",
      "    shrinking=True, tol=0.001, verbose=False) \n",
      "Score=0.8210202761000862 \n",
      "#################################################################################\n",
      "\n",
      "RANDOM FOREST\n",
      "Fitting 4 folds for each of 42 candidates, totalling 168 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 168 out of 168 | elapsed:    8.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False) \n",
      "Score=0.8433875858673022 \n",
      "#################################################################################\n",
      "\n",
      "XGBOOST\n",
      "Fitting 4 folds for each of 250 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   59.3s\n",
      "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=42,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1) \n",
      "Score=0.8325409695826282 \n",
      "#################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_model=[]\n",
    "\n",
    "for model, arg in models.items():\n",
    "    print(model.upper())\n",
    "    best_param, metric = fine_tuning(arg[\"algo\"], arg[\"parameter\"], X_train, y_train, 250, \"f1\", 4)\n",
    "    list_model.append([model, metric, best_param])\n",
    "    print(\"#################################################################################\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CCI9nD-xoq8q"
   },
   "source": [
    "# Create CatBoost model and Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwuyEZ8dA4Yj"
   },
   "source": [
    "## Install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kEkUokH1w1fd"
   },
   "outputs": [],
   "source": [
    "!pip install catboost -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_y3NzzI9bJT"
   },
   "source": [
    "## Change target label value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h_kegEOj56fe"
   },
   "outputs": [],
   "source": [
    "###### BEFORE\n",
    "# '1' = LAYAK , '2' = TIDAK LAYAK\n",
    "###### AFTER\n",
    "# '1' = LAYAK , '0' = TIDAK LAYAK\n",
    "y_train_un = np.where(y_train_un==2, 0, y_train_un)\n",
    "y_test_un = np.where(y_test_un==2, 0, y_test_un)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e18uzCB0BCkt"
   },
   "source": [
    "## Fine-Tuning CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "QWqvBIo2iQzu",
    "outputId": "b4c16258-ce3f-4e94-ef8e-9ef6a2b1ebfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tloss: 0.8557692\tbest: 0.8557692 (0)\ttotal: 15.7s\tremaining: 7m 34s\n",
      "1:\tloss: 0.8341232\tbest: 0.8557692 (0)\ttotal: 1m 3s\tremaining: 14m 49s\n",
      "2:\tloss: 0.8458150\tbest: 0.8557692 (0)\ttotal: 3m 15s\tremaining: 29m 19s\n",
      "3:\tloss: 0.8584906\tbest: 0.8584906 (3)\ttotal: 3m 27s\tremaining: 22m 28s\n",
      "4:\tloss: 0.8682927\tbest: 0.8682927 (4)\ttotal: 3m 34s\tremaining: 17m 50s\n",
      "5:\tloss: 0.8316832\tbest: 0.8682927 (4)\ttotal: 3m 40s\tremaining: 14m 42s\n",
      "6:\tloss: 0.8487805\tbest: 0.8682927 (4)\ttotal: 4m 13s\tremaining: 13m 53s\n",
      "7:\tloss: 0.8405797\tbest: 0.8682927 (4)\ttotal: 4m 29s\tremaining: 12m 19s\n",
      "8:\tloss: 0.8487805\tbest: 0.8682927 (4)\ttotal: 6m 21s\tremaining: 14m 50s\n",
      "9:\tloss: 0.8173077\tbest: 0.8682927 (4)\ttotal: 10m 37s\tremaining: 21m 15s\n",
      "10:\tloss: 0.8430493\tbest: 0.8682927 (4)\ttotal: 10m 58s\tremaining: 18m 56s\n",
      "11:\tloss: 0.8446602\tbest: 0.8682927 (4)\ttotal: 11m 4s\tremaining: 16m 36s\n",
      "12:\tloss: 0.8487805\tbest: 0.8682927 (4)\ttotal: 11m 11s\tremaining: 14m 37s\n",
      "13:\tloss: 0.8599034\tbest: 0.8682927 (4)\ttotal: 11m 29s\tremaining: 13m 7s\n",
      "14:\tloss: 0.8625592\tbest: 0.8682927 (4)\ttotal: 11m 35s\tremaining: 11m 35s\n",
      "15:\tloss: 0.8396226\tbest: 0.8682927 (4)\ttotal: 18m 21s\tremaining: 16m 3s\n",
      "16:\tloss: 0.8479263\tbest: 0.8682927 (4)\ttotal: 18m 49s\tremaining: 14m 23s\n",
      "17:\tloss: 0.8543689\tbest: 0.8682927 (4)\ttotal: 19m 55s\tremaining: 13m 16s\n",
      "18:\tloss: 0.8356808\tbest: 0.8682927 (4)\ttotal: 23m\tremaining: 13m 19s\n",
      "19:\tloss: 0.8446602\tbest: 0.8682927 (4)\ttotal: 24m 26s\tremaining: 12m 13s\n",
      "20:\tloss: 0.8390244\tbest: 0.8682927 (4)\ttotal: 24m 33s\tremaining: 10m 31s\n",
      "21:\tloss: 0.8396226\tbest: 0.8682927 (4)\ttotal: 27m 33s\tremaining: 10m 1s\n",
      "22:\tloss: 0.8416290\tbest: 0.8682927 (4)\ttotal: 27m 41s\tremaining: 8m 25s\n",
      "23:\tloss: 0.8613861\tbest: 0.8682927 (4)\ttotal: 28m 33s\tremaining: 7m 8s\n",
      "24:\tloss: 0.8651163\tbest: 0.8682927 (4)\ttotal: 29m\tremaining: 5m 48s\n",
      "25:\tloss: 0.8487805\tbest: 0.8682927 (4)\ttotal: 31m 27s\tremaining: 4m 50s\n",
      "26:\tloss: 0.8476190\tbest: 0.8682927 (4)\ttotal: 31m 49s\tremaining: 3m 32s\n",
      "27:\tloss: 0.8543689\tbest: 0.8682927 (4)\ttotal: 42m 2s\tremaining: 3m\n",
      "28:\tloss: 0.8585366\tbest: 0.8682927 (4)\ttotal: 42m 23s\tremaining: 1m 27s\n",
      "29:\tloss: 0.8415842\tbest: 0.8682927 (4)\ttotal: 42m 34s\tremaining: 0us\n",
      "Estimating final quality...\n"
     ]
    }
   ],
   "source": [
    "import catboost\n",
    "import scipy\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(eval_metric='F1', task_type='GPU')\n",
    "train_pool = catboost.Pool(X_train_un, y_train_un, cat_features = [2,3,4,5,6,7,8,9,10,11,12])\n",
    "test_pool = catboost.Pool(X_test_un, cat_features = [2,3,4,5,6,7,8,9,10,11,12])\n",
    "\n",
    "parameter = {\n",
    "    'learning_rate': scipy.stats.uniform(0.1, 0.3),\n",
    "    'depth': scipy.stats.randint(8, 16),\n",
    "    'l2_leaf_reg':scipy.stats.uniform(1, 10),\n",
    "    'one_hot_max_size': [2, 5, 10],\n",
    "    'iterations' : [50, 75, 100, 150] #number of trees\n",
    "}\n",
    "\n",
    "randomized_search_results = model.randomized_search(\n",
    "    parameter,\n",
    "    train_pool,\n",
    "    n_iter=30,\n",
    "    shuffle=True,\n",
    "    cv=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8aO1TIlnLYNJ"
   },
   "source": [
    "## Fit CatBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "3ftoj3GzUtC3",
    "outputId": "01b146ea-5391-4857-b2ef-fa07ab584079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6143064\ttotal: 10.6ms\tremaining: 518ms\n",
      "1:\tlearn: 0.5805439\ttotal: 20.3ms\tremaining: 486ms\n",
      "2:\tlearn: 0.5513370\ttotal: 29.9ms\tremaining: 468ms\n",
      "3:\tlearn: 0.5280817\ttotal: 39.7ms\tremaining: 456ms\n",
      "4:\tlearn: 0.5096263\ttotal: 49.2ms\tremaining: 442ms\n",
      "5:\tlearn: 0.4959403\ttotal: 58.8ms\tremaining: 431ms\n",
      "6:\tlearn: 0.4780001\ttotal: 68.5ms\tremaining: 421ms\n",
      "7:\tlearn: 0.4651641\ttotal: 78.2ms\tremaining: 410ms\n",
      "8:\tlearn: 0.4502458\ttotal: 87.7ms\tremaining: 400ms\n",
      "9:\tlearn: 0.4388404\ttotal: 97.3ms\tremaining: 389ms\n",
      "10:\tlearn: 0.4296538\ttotal: 107ms\tremaining: 379ms\n",
      "11:\tlearn: 0.4197322\ttotal: 116ms\tremaining: 368ms\n",
      "12:\tlearn: 0.4109223\ttotal: 126ms\tremaining: 358ms\n",
      "13:\tlearn: 0.4078302\ttotal: 131ms\tremaining: 336ms\n",
      "14:\tlearn: 0.3952962\ttotal: 140ms\tremaining: 328ms\n",
      "15:\tlearn: 0.3847701\ttotal: 150ms\tremaining: 319ms\n",
      "16:\tlearn: 0.3758305\ttotal: 162ms\tremaining: 314ms\n",
      "17:\tlearn: 0.3682390\ttotal: 171ms\tremaining: 305ms\n",
      "18:\tlearn: 0.3611891\ttotal: 181ms\tremaining: 296ms\n",
      "19:\tlearn: 0.3513389\ttotal: 191ms\tremaining: 286ms\n",
      "20:\tlearn: 0.3441142\ttotal: 201ms\tremaining: 277ms\n",
      "21:\tlearn: 0.3356773\ttotal: 214ms\tremaining: 273ms\n",
      "22:\tlearn: 0.3283266\ttotal: 224ms\tremaining: 263ms\n",
      "23:\tlearn: 0.3212130\ttotal: 235ms\tremaining: 255ms\n",
      "24:\tlearn: 0.3143254\ttotal: 245ms\tremaining: 245ms\n",
      "25:\tlearn: 0.3091271\ttotal: 254ms\tremaining: 235ms\n",
      "26:\tlearn: 0.3037395\ttotal: 264ms\tremaining: 225ms\n",
      "27:\tlearn: 0.2957747\ttotal: 274ms\tremaining: 215ms\n",
      "28:\tlearn: 0.2885861\ttotal: 283ms\tremaining: 205ms\n",
      "29:\tlearn: 0.2835116\ttotal: 293ms\tremaining: 195ms\n",
      "30:\tlearn: 0.2775952\ttotal: 302ms\tremaining: 185ms\n",
      "31:\tlearn: 0.2722492\ttotal: 312ms\tremaining: 175ms\n",
      "32:\tlearn: 0.2656096\ttotal: 322ms\tremaining: 166ms\n",
      "33:\tlearn: 0.2609916\ttotal: 332ms\tremaining: 156ms\n",
      "34:\tlearn: 0.2567177\ttotal: 349ms\tremaining: 149ms\n",
      "35:\tlearn: 0.2523535\ttotal: 363ms\tremaining: 141ms\n",
      "36:\tlearn: 0.2478271\ttotal: 373ms\tremaining: 131ms\n",
      "37:\tlearn: 0.2431906\ttotal: 383ms\tremaining: 121ms\n",
      "38:\tlearn: 0.2389287\ttotal: 392ms\tremaining: 111ms\n",
      "39:\tlearn: 0.2340606\ttotal: 402ms\tremaining: 100ms\n",
      "40:\tlearn: 0.2292273\ttotal: 415ms\tremaining: 91.1ms\n",
      "41:\tlearn: 0.2259694\ttotal: 425ms\tremaining: 80.9ms\n",
      "42:\tlearn: 0.2229039\ttotal: 434ms\tremaining: 70.7ms\n",
      "43:\tlearn: 0.2203529\ttotal: 444ms\tremaining: 60.5ms\n",
      "44:\tlearn: 0.2173053\ttotal: 453ms\tremaining: 50.4ms\n",
      "45:\tlearn: 0.2141677\ttotal: 463ms\tremaining: 40.3ms\n",
      "46:\tlearn: 0.2108876\ttotal: 473ms\tremaining: 30.2ms\n",
      "47:\tlearn: 0.2079734\ttotal: 482ms\tremaining: 20.1ms\n",
      "48:\tlearn: 0.2040236\ttotal: 492ms\tremaining: 10ms\n",
      "49:\tlearn: 0.2015883\ttotal: 502ms\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# Get best parameter of models\n",
    "best_parameter = randomized_search_results['params']\n",
    "# Create CatBoostClassifier\n",
    "model_catboost = CatBoostClassifier(**best_parameter, task_type='GPU')\n",
    "# Fit CatBoost\n",
    "model_catboost.fit(X_train_un, y_train_un, cat_features = [2,3,4,5,6,7,8,9,10,11,12])\n",
    "\n",
    "# Append score and model\n",
    "list_model.append(['CatBoost', model_catboost.get_best_score(), model_catboost])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "voYUpPY6oenE"
   },
   "source": [
    "# Testing all models and evaluate performance to Unknown data (testing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "YZpcVvurYyso",
    "outputId": "5b074b2b-79d7-4d17-d8e0-0320674f0897"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Performance SVC\n",
      "F1-Score =0.8462\n",
      "\n",
      "Evaluation Performance Random Forest\n",
      "F1-Score =0.8459\n",
      "\n",
      "Evaluation Performance XGBoost\n",
      "F1-Score =0.8303\n",
      "\n",
      "Evaluation Performance CatBoost\n",
      "F1-Score =0.8551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Predict\n",
    "for i in list_model:\n",
    "  if i[0] != 'CatBoost':\n",
    "    y_pred = i[2].predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "  else :\n",
    "    y_pred = i[2].predict(X_test_un, prediction_type='Class')\n",
    "    f1 = f1_score(y_test_un, y_pred)\n",
    "    \n",
    "  print(\"Evaluation Performance\", i[0])\n",
    "  print(\"F1-Score ={:.4f}\".format(f1))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZW1thl0rLsb9"
   },
   "source": [
    "# Result from Evaluation Performance\n",
    "CatBoost has the highest F1-Score because the ability for handle categorical data and has gradient boosting concept, but we must note it need more computation time rather than other algorithm\n",
    "\n",
    "But CatBoost can performance really well on large dataset and more robust to prevent overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eXnMgJyoMxMZ"
   },
   "source": [
    "# Save CatBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sN-CKOlFMcWP"
   },
   "outputs": [],
   "source": [
    "model_catboost.save_model(\"drive/My Drive/Colab Notebooks/credit_scoring/model_cs\",\n",
    "           format=\"cbm\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model_CS.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
